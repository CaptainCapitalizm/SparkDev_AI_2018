{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#from skimage import data, util\n",
    "#from skimage.measure import label, regionprops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MSER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Getting the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MSER will detect clusters of data where in this case, individual words = clusters of data.\n",
    "\n",
    "#MSER object\n",
    "mser = cv2.MSER_create()\n",
    "\n",
    "#The image to read\n",
    "img = cv2.imread('test5.jpg') \n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #gray scale the image\n",
    "\n",
    "vis = img.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Regions (Words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                      Find Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coordinates, bboxes = mser.detectRegions(img_gray) #words in the gray scale image\n",
    "\n",
    "coords = []\n",
    "for coord in coordinates:\n",
    "    bbox = cv2.boundingRect(coord)\n",
    "    x,y,w,h = bbox\n",
    "    if w < 20 or h < 20 or w/h > 10 or h/w > 10:\n",
    "        continue\n",
    "    coords.append(coord)\n",
    "    \n",
    "colors = [[43, 43, 200], [43, 75, 200], [43, 106, 200], [43, 137, 200], [43, 169, 200], [43, 200, 195], [43, 200, 163], [43, 200, 132], [43, 200, 101], [43, 200, 69], [54, 200, 43], [85, 200, 43], [116, 200, 43], [148, 200, 43], [179, 200, 43], [200, 184, 43], [200, 153, 43], [200, 122, 43], [200, 90, 43], [200, 59, 43], [200, 43, 64], [200, 43, 95], [200, 43, 127], [200, 43, 158], [200, 43, 190], [174, 43, 200], [142, 43, 200], [111, 43, 200], [80, 43, 200], [43, 43, 200]]\n",
    "\n",
    "np.random.seed(0)\n",
    "canvas1 = img.copy()\n",
    "canvas2 = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)\n",
    "canvas3 = np.zeros_like(img)\n",
    "\n",
    "for cnt in coords:\n",
    "    xx = cnt[:,0]\n",
    "    yy = cnt[:,1]\n",
    "    color = colors[np.random.choice(len(colors))]\n",
    "    canvas1[yy, xx] = color\n",
    "    canvas2[yy, xx] = color\n",
    "    canvas3[yy, xx] = color\n",
    "    \n",
    "cv2.imshow('img', canvas1)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Region Properties to Reduce Noise Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mserStats = regionprops(bboxes) #properties of each bbox as a tuple of regions\n",
    "bboxStats = []\n",
    "bboxStats.append(mserStats[0].bbox)\n",
    "print(bboxes)\n",
    "for i in range(1, len(mserStats)):\n",
    "    myInput = []\n",
    "    myInput.append(mserStats[i].bbox)\n",
    "    bboxStats = np.concatenate((bboxStats, myInput))\n",
    "\n",
    "w = bboxStats[:, 2]\n",
    "h = bboxStats[:, 3]\n",
    "aspectRatio = w/h\n",
    "print(len(bboxes))\n",
    "filterIdx = aspectRatio.conj().transpose() > 30\n",
    "#print(filterIdx)\n",
    "\n",
    "for i in range(0, len(mserStats)):\n",
    "    #print(mserStats[i].eccentricity)\n",
    "    filterIdx[i] = filterIdx[i] or (mserStats[i].eccentricity > 1)\n",
    "    filterIdx[i] = filterIdx[i] or (mserStats[i].solidity < .1)\n",
    "    filterIdx[i] = filterIdx[i] or ((mserStats[i].extent < 0.2) | (mserStats[i].extent > 0.9))\n",
    "    filterIdx[i] = filterIdx[i] or (mserStats[i].euler_number < -4)\n",
    "\n",
    "print(filterIdx)\n",
    "#mserStats[filterIdx] = []\n",
    "#mserRegions[filterIdx] = []\n",
    "for j in range(0, len(mserStats)):\n",
    "    if(filterIdx[j] == True):\n",
    "        mserStats[j] = []\n",
    "        #print(j)\n",
    "        np.delete(bboxes, [0])\n",
    "\n",
    "print(len(bboxes))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, bboxes = mser.detectRegions(img_gray)\n",
    "bboxes_list = []\n",
    "heights = []\n",
    "\n",
    "for bbox in bboxes:\n",
    "    x, y, w, h = bbox\n",
    "    bboxes_list.append([x, y, x + w, y + h])\n",
    "    heights.append(h)\n",
    "    cv2.rectangle(vis, (x, y), ((x+h), (y+w)), (0, 255, 0), 2)\n",
    "print(len(bboxes))\n",
    "heights = sorted(heights)\n",
    "median_height = heights[int(len(heights) / 2)] / 2\n",
    "\n",
    "#hulls = [cv2.convexHull(p.reshape(-1, 1, 2)) for p in regions]\n",
    "#cv2.polylines(vis, hulls, 1, (0, 255, 0))\n",
    "cv2.imshow('img', vis)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#mask = np.zeros((img.shape[0], img.shape[1], 1), dtype = np.uint8)\n",
    "#for contour in hulls:\n",
    "    #cv2.drawContours(mask, [contour], -1, (255, 255, 255), -1)\n",
    "#text_only = cv2.bitwise_and(img, img, mask = mask)\n",
    "#cv2.imshow(\"text only\", text_only)\n",
    "#cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-0c625ba110fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mboxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpick\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"int\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m \u001b[0mbboxes_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnon_max_suppression_fast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbboxes_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.3\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Group the bounding boxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstartX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstartY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstartX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstartY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mendX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-0c625ba110fe>\u001b[0m in \u001b[0;36mnon_max_suppression_fast\u001b[1;34m(boxes, overlapThresh)\u001b[0m\n\u001b[0;32m     19\u001b[0m    \u001b[1;31m# if the bounding boxes integers, convert them to floats --\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m    \u001b[1;31m# this is important since we'll be doing a bunch of divisions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m    \u001b[1;32mif\u001b[0m \u001b[0mboxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"i\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m       \u001b[0mboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "def grouper(iterable, interval=0):\n",
    "    prev = None\n",
    "    group = []\n",
    "    for item in iterable:\n",
    "        if not prev or abs(item[1] - prev[1]) <= interval:\n",
    "            group.append(item)\n",
    "        else:\n",
    "            yield group\n",
    "            group = [item]\n",
    "        prev = item\n",
    "    if group:\n",
    "        yield group\n",
    "\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "   # if there are no boxes, return an empty list\n",
    "   if len(boxes) == 0:\n",
    "      return []\n",
    "\n",
    "   # if the bounding boxes integers, convert them to floats --\n",
    "   # this is important since we'll be doing a bunch of divisions\n",
    "   if boxes.dtype.kind == \"i\":\n",
    "      boxes = boxes.astype(\"float\")\n",
    "#  \n",
    "   # initialize the list of picked indexes   \n",
    "   pick = []\n",
    "\n",
    "   # grab the coordinates of the bounding boxes\n",
    "   x1 = boxes[:,0]\n",
    "   y1 = boxes[:,1]\n",
    "   x2 = boxes[:,2]\n",
    "   y2 = boxes[:,3]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "   # boxes by the bottom-right y-coordinate of the bounding box\n",
    "   area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "   idxs = np.argsort(y2)\n",
    "\n",
    "   # keep looping while some indexes still remain in the indexes\n",
    "   # list\n",
    "   while len(idxs) > 0:\n",
    "      # grab the last index in the indexes list and add the\n",
    "      # index value to the list of picked indexes\n",
    "      last = len(idxs) - 1\n",
    "      i = idxs[last]\n",
    "      pick.append(i)\n",
    "\n",
    "      # find the largest (x, y) coordinates for the start of\n",
    "      # the bounding box and the smallest (x, y) coordinates\n",
    "      # for the end of the bounding box\n",
    "      xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "      yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "      xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "      yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "      \n",
    "      # compute the width and height of the bounding box\n",
    "      w = np.maximum(0, xx2 - xx1 + 1)\n",
    "      h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "      # compute the ratio of overlap\n",
    "      overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "      # delete all indexes from the index list that have\n",
    "      idxs = np.delete(idxs, np.concatenate(([last],\n",
    "         np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "   # return only the bounding boxes that were picked using the\n",
    "   # integer data type\n",
    "   return boxes[pick].astype(\"int\")\n",
    "\n",
    "bboxes_list = non_max_suppression_fast(bboxes_list, .3)  # Group the bounding boxes\n",
    "for (startX, startY, endX, endY) in bboxes:\n",
    "    cv2.rectangle(vis, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "    \n",
    "print(len(bboxes))\n",
    "\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "144px",
    "left": "1266px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
