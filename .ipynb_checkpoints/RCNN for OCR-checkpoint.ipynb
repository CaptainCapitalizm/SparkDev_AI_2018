{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree\n",
    "from xml.dom import minidom\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pandas import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xmldoc = minidom.parse('MiracleDataFile.xml')\n",
    "itemlist = xmldoc.getElementsByTagName('word')\n",
    "\n",
    "    # In[67]:\n",
    "\n",
    "\n",
    "    #images_labels = []\n",
    "    #images_labels.append([]) #making a 2D array in python\n",
    "    #images_labels.append([])\n",
    "    \n",
    "tags = []\n",
    "words = []\n",
    "for z in itemlist:\n",
    "    tags.append(z.attributes['id'].value)\n",
    "    words.append(z.attributes['text'].value)\n",
    "\n",
    "    #print(store)\n",
    "df = DataFrame({'Word Id': tags, 'Text': words})\n",
    "df = DataFrame.drop_duplicates(df)\n",
    "df = df.sort_values(by = ['Word Id'], ascending=[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [] \n",
    "imgs = []\n",
    "\n",
    "image_id_real = []\n",
    "\n",
    "for file in os.listdir('C:/Users/Adrian/Desktop/SparkDevAI2018/TestSetWords/TestSetWords'):\n",
    "        for file2 in os.listdir('C:/Users/Adrian/Desktop/SparkDevAI2018/TestSetWords/TestSetWords/' + file):\n",
    "            for image in os.listdir('C:/Users/Adrian/Desktop/SparkDevAI2018/TestSetWords/TestSetWords/' + file + '/' + file2):\n",
    "                imgs.append(cv2.imread('C:/Users/Adrian/Desktop/SparkDevAI2018/TestSetWords/TestSetWords/' + file + '/' + file2+ '/'+image))\n",
    "                image_id = image.split('.')\n",
    "                image_id_real.append(image_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in image_id_real:\n",
    "    row = df[df['Word Id'].str.match(index)]\n",
    "    word = row.iloc[0]['Text']\n",
    "    labels.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "letters = ''\n",
    "\n",
    "for x in labels:\n",
    "    letters += x\n",
    "\n",
    "letters = \"\".join(set(letters))\n",
    "letters = \"\".join(sorted(letters))\n",
    "\n",
    "print(len(letters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labels_to_text(labels):\n",
    "    return ''.join(list(map(lambda x: letters[int(x)], labels)))\n",
    "\n",
    "def text_to_labels(text):\n",
    "    return list(map(lambda x: letters.index(x), text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4824, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "img_data = []\n",
    "\n",
    "for img in imgs:\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (128, 64))\n",
    "    data = np.asarray(img, dtype = \"int32\")\n",
    "    #data /= 255\n",
    "    img_data.append(data)\n",
    "\n",
    "img_data = np.array(img_data)\n",
    "print(img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_encoded = []\n",
    "for word in labels:\n",
    "    labels_encoded.append(text_to_labels(word))\n",
    "labels_encoded = np.array(labels_encoded) #object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(max(labels_encoded, key = tuple)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into X and Y Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = img_data, labels_encoded\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= .15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D #convolution 2d for images\n",
    "from keras.layers import MaxPooling2D #for pooling\n",
    "from keras.layers import Flatten #for flattening the pooling into the inputs of full layer\n",
    "from keras.layers import Dense #to create hidden layers, into ann\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def functional():\n",
    "    img_h = 64\n",
    "    img_w = 128\n",
    "    # Network parameters\n",
    "    conv_filters = 16\n",
    "    kernel_size = (3, 3)\n",
    "    pool_size = 2\n",
    "    time_dense_size = 32\n",
    "    rnn_size = 512\n",
    "        \n",
    "    batch_size = 32\n",
    "    downsample_factor = pool_size ** 2\n",
    "\n",
    "    act = 'relu'\n",
    "    input_data = Input(name='the_input', shape=(img_w, img_h, 1), dtype='float32')\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv1')(input_data)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv2')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
    "    inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "    # cuts down input size going into RNN:\n",
    "    inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "    # Two layers of bidirecitonal GRUs\n",
    "    # GRU seems to work as well, if not better than LSTM:\n",
    "    gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
    "    gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
    "    gru1_merged = add([gru_1, gru_1b])\n",
    "    gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    inner = Dense(71, kernel_initializer='he_normal',\n",
    "                  name='dense2')(concatenate([gru_2, gru_2b]))\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "    Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[9], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    # Keras doesn't currently support loss funcs with extra parameters\n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    # clipnorm seems to speeds up convergence\n",
    "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\n",
    "    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "    \n",
    "    \n",
    "    # captures output of softmax so we can decode the output during visualization\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(img_w, img_h, max_text_len):\n",
    "    #Parameters\n",
    "    conv_filters = 16\n",
    "    kernel_size = (3, 3)\n",
    "    pool_size = 2\n",
    "    time_dense_size = 32\n",
    "    rnn_size = 512\n",
    "    #Initializing CNN\n",
    "    classifier = Sequential()\n",
    "    \n",
    "    #Step 1\n",
    "    classifier.add(Convolution2D(conv_filters, kernel_size, input_shape=(img_w, img_h, 1), padding = 'same', activation=\"relu\",  kernel_initializer='he_normal'))\n",
    "    \n",
    "    print(classifier.layers[0].shape)\n",
    "    #Step2 MAXadd(Convolution2D(32, (3, 3), activation=\"relu\"))\n",
    "    #POOLING\n",
    "    classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    #to make more accurate results, another convolutional layer.\n",
    "    classifier.add(Convolution2D(conv_filters, kernel_size, padding = 'same', activation=\"relu\", kernel_initializer='he_normal'))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
    "    \n",
    "    #print(conv_to_rnn_dims)\n",
    "    \n",
    "    classifier.add(Reshape(target_shape=conv_to_rnn_dims))\n",
    "    \n",
    "    #1 par how many neurons in hidden layer 128 gotten from experimentation more than 100\n",
    "    classifier.add(Dense(units = 32, activation = 'relu'))\n",
    "        \n",
    "    # Adding the first LSTM layer and some Dropout regularisation\n",
    "    classifier.add(Bidirectional(LSTM(units = 512, return_sequences = True, kernel_initializer='he_normal')))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    \n",
    "    # Adding a second LSTM layer and some Dropout regularisation\n",
    "    classifier.add(Bidirectional(LSTM(units = 512, return_sequences = True, kernel_initializer='he_normal')))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    \n",
    "    classifier.add(Flatten())\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = len(letters)+1, activation = 'softmax', kernel_initializer='he_normal'))\n",
    "    #classifier.add(Activation('softmax'))\n",
    "    \n",
    "    #labels = Input(name='the_labels', shape=[max_text_len], dtype='float32')\n",
    "    #print(labels)\n",
    "    #input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    #print(input_length)\n",
    "    #label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    #print(label_length)\n",
    "    \n",
    "    \n",
    "    print(classifier.summary())\n",
    "    \n",
    "    #intermediate_layer_model = Model(inputs=classifier.input, outputs=classifier.layers[11].output)\n",
    "    #y_pred = classifier.layers[11].get_output_at(0)\n",
    "\n",
    "    #y_pred = classifier.layers[11].get_output_at(0)\n",
    "\n",
    "    #print(y_pred)\n",
    "    \n",
    "    #classifier.add(Lambda(ctc_lambda_func(y_pred, labels, input_length, label_length), output_shape=(1,)))\n",
    "    \n",
    "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "    \n",
    "    #model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "    # Compiling\n",
    "    #classifier.compile(loss= {'ctc': lambda y_true, y_pred: y_pred}, optimizer= sgd)\n",
    "    classifier.compile(loss = 'categorical_crossentropy', optimizer = sgd)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Let's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Conv2D' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-242-5380fb57978a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-241-8d5dea3c18a7>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(img_w, img_h, max_text_len)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_filters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'he_normal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;31m#Step2 MAXadd(Convolution2D(32, (3, 3), activation=\"relu\"))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#POOLING\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Conv2D' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model = model(128, 64, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4100, 128, 64, 1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-243-849d17bf9cf6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print(X_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "X_train = np.reshape(X_train, (4100, 128, 64, 1))\n",
    "\n",
    "#y_train = np.array(y_train)\n",
    "#print(X_train)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
